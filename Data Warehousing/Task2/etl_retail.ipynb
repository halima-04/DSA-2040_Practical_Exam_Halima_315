{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8202fba7",
   "metadata": {},
   "source": [
    "## Step 1 — Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd457d",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Read the dataset (Online_Retail.csv) from disk into a pandas DataFrame.\n",
    "* Remove rows missing essential values:\n",
    "* InvoiceNo → needed to identify transactions.\n",
    "* StockCode → product identification.\n",
    "* Quantity and UnitPrice → required for sales calculations.\n",
    "* InvoiceDate → needed for time-based analysis.\n",
    "* Convert InvoiceDate to a proper datetime type so we can filter and group by time later.\n",
    "* Remove any rows where the date could not be parsed.\n",
    "\n",
    "## Why we do it:\n",
    "* Ensures we are working only with valid, complete data before transformations.\n",
    "* Makes sure the InvoiceDate column is in a format that allows filtering and aggregations.\n",
    "* Avoids issues in later steps from missing or invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81a11f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Extract] Raw rows read: 541909\n",
      "[Extract] Rows after cleaning: 232959\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-01-12 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-01-12 08:26:00       3.39     17850.0  United Kingdom  \n",
      "2 2010-01-12 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-01-12 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-01-12 08:26:00       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "CURRENT_DATE = datetime(2025, 8, 12)\n",
    "\n",
    "def extract(file_path):\n",
    "    \"\"\"\n",
    "    Step 1: Extract data from Online_Retail.csv\n",
    "    - Reads the CSV file into a pandas DataFrame\n",
    "    - Removes rows missing important fields\n",
    "    - Converts InvoiceDate to datetime\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read CSV with correct encoding to handle special characters like £\n",
    "    df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "    print(f\"[Extract] Raw rows read: {len(df)}\")\n",
    "    \n",
    "    # Drop rows with missing values in critical columns\n",
    "    df = df.dropna(subset=[\"InvoiceNo\", \"StockCode\", \"Quantity\", \"InvoiceDate\", \"UnitPrice\"])\n",
    "    \n",
    "    # Convert InvoiceDate to datetime format\n",
    "    df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"], errors=\"coerce\")\n",
    "    \n",
    "    # Remove rows where the date couldn't be parsed\n",
    "    df = df.dropna(subset=[\"InvoiceDate\"])\n",
    "    \n",
    "    print(f\"[Extract] Rows after cleaning: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Run extraction\n",
    "df_extracted = extract(\n",
    "    r\"C:\\Users\\Salma\\New folder\\OneDrive\\Desktop\\DSA 2040_Practical_Exam\\DSA-2040_Practical_Exam_Halima_315\\Online_Retail.csv\"\n",
    ")\n",
    "\n",
    "# Show first 5 cleaned rows\n",
    "print(df_extracted.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474a7b3",
   "metadata": {},
   "source": [
    "## Step 2 — Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f46a7b",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Remove invalid transactions:\n",
    "* Negative or zero Quantity values.\n",
    "* Zero or negative UnitPrice.\n",
    "* Create a new column:\n",
    "* TotalSales = Quantity * UnitPrice → This is the key sales measure.\n",
    "* Filter transactions to the last year relative to 2025-08-12 (exam requirement).\n",
    "* Create dimension-like tables:\n",
    "* CustomerDim: unique CustomerID and Country.\n",
    "* TimeDim: unique dates with TimeID, Month, Quarter, Year for time-based OLAP.\n",
    "* Prepare fact table:\n",
    "* SalesFact: contains CustomerID, TimeID, Quantity, and TotalSales.\n",
    "\n",
    "## Why we do it:\n",
    "* Removes bad data so our metrics are accurate.\n",
    "* Adds new calculated metrics for reporting.\n",
    "* Structures the data into star schema format to make OLAP queries easier in Task 3.\n",
    "* Filters for recent transactions to keep analysis relevant and within the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11184ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    \"\"\"\n",
    "    Step 2: Transform the extracted data.\n",
    "    Cleans invalid values, calculates TotalSales,\n",
    "    filters data to the last year, and creates dimension/fact tables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove invalid rows (negative quantities or zero price)\n",
    "    df = df[(df[\"Quantity\"] > 0) & (df[\"UnitPrice\"] > 0)]\n",
    "    \n",
    "    # Create new measure column\n",
    "    df[\"TotalSales\"] = df[\"Quantity\"] * df[\"UnitPrice\"]\n",
    "    \n",
    "    # Filter data for last year from CURRENT_DATE\n",
    "    start_date = CURRENT_DATE - timedelta(days=365)\n",
    "    df = df[(df[\"InvoiceDate\"] >= start_date) & (df[\"InvoiceDate\"] <= CURRENT_DATE)]\n",
    "    \n",
    "    # Create Customer Dimension table (unique customers and country)\n",
    "    customer_dim = df[[\"CustomerID\", \"Country\"]].drop_duplicates().dropna()\n",
    "    \n",
    "    # Create Time Dimension table (unique dates with breakdowns)\n",
    "    time_dim = pd.DataFrame({\n",
    "        \"TimeID\": df[\"InvoiceDate\"].dt.strftime(\"%Y%m%d\").astype(int),\n",
    "        \"Date\": df[\"InvoiceDate\"].dt.date,\n",
    "        \"Month\": df[\"InvoiceDate\"].dt.month,\n",
    "        \"Quarter\": ((df[\"InvoiceDate\"].dt.month - 1)//3 + 1),\n",
    "        \"Year\": df[\"InvoiceDate\"].dt.year\n",
    "    }).drop_duplicates()\n",
    "    \n",
    "    # Create Sales Fact table with foreign keys and measures\n",
    "    sales_fact = df[[\"CustomerID\", \"Quantity\", \"TotalSales\"]].copy()\n",
    "    sales_fact[\"TimeID\"] = df[\"InvoiceDate\"].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    \n",
    "    # Log table sizes for verification\n",
    "    print(f\"[Transform] Customers: {len(customer_dim)}, Time records: {len(time_dim)}, SalesFact rows: {len(sales_fact)}\")\n",
    "    \n",
    "    return customer_dim, time_dim, sales_fact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef70eae",
   "metadata": {},
   "source": [
    "## Step 3 — Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3b914",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Connect to a SQLite database (retail_dw.db).\n",
    "* Create tables:\n",
    "* CustomerDim\n",
    "* TimeDim\n",
    "* SalesFact\n",
    "* Load the cleaned/transformed data into these tables.\n",
    "* Enforce foreign key constraints to maintain referential integrity.\n",
    "\n",
    "## Why we do it:\n",
    "* Moves data into a data warehouse structure for analysis.\n",
    "* Allows running SQL queries efficiently in later steps (Task 3).\n",
    "* Ensures we follow proper relational database design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b77bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def load(customer_dim, time_dim, sales_fact, db_name=\"retail_dw.db\"):\n",
    "    \"\"\"\n",
    "    Step 3: Load transformed data into SQLite database.\n",
    "    Creates tables and inserts dimension and fact data, ensuring keys match.\n",
    "    \"\"\"\n",
    "    # Ensure unique rows for dimensions\n",
    "    customer_dim = customer_dim.drop_duplicates(subset=[\"CustomerID\"])\n",
    "    time_dim = time_dim.drop_duplicates(subset=[\"TimeID\"])\n",
    "\n",
    "    # Connect to SQLite (creates db if not exists)\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the schema\n",
    "    cursor.executescript(\"\"\"\n",
    "    DROP TABLE IF EXISTS SalesFact;\n",
    "    DROP TABLE IF EXISTS TimeDim;\n",
    "    DROP TABLE IF EXISTS CustomerDim;\n",
    "\n",
    "    CREATE TABLE CustomerDim (\n",
    "        CustomerID INTEGER PRIMARY KEY,\n",
    "        Country TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE TimeDim (\n",
    "        TimeID INTEGER PRIMARY KEY,\n",
    "        Date TEXT,\n",
    "        Month INTEGER,\n",
    "        Quarter INTEGER,\n",
    "        Year INTEGER\n",
    "    );\n",
    "\n",
    "    CREATE TABLE SalesFact (\n",
    "        SalesID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        CustomerID INTEGER,\n",
    "        TimeID INTEGER,\n",
    "        Quantity INTEGER,\n",
    "        TotalSales REAL,\n",
    "        FOREIGN KEY (CustomerID) REFERENCES CustomerDim(CustomerID),\n",
    "        FOREIGN KEY (TimeID) REFERENCES TimeDim(TimeID)\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    # Load data into dimension and fact tables\n",
    "    customer_dim.to_sql(\"CustomerDim\", conn, if_exists=\"append\", index=False)\n",
    "    time_dim.to_sql(\"TimeDim\", conn, if_exists=\"append\", index=False)\n",
    "    sales_fact.to_sql(\"SalesFact\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"[Load] Data loaded into {db_name} successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
