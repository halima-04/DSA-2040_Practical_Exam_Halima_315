{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8202fba7",
   "metadata": {},
   "source": [
    "## Step 1 — Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd457d",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Read the dataset (Online_Retail.csv) from disk into a pandas DataFrame.\n",
    "* Remove rows missing essential values:\n",
    "* InvoiceNo → needed to identify transactions.\n",
    "* StockCode → product identification.\n",
    "* Quantity and UnitPrice → required for sales calculations.\n",
    "* InvoiceDate → needed for time-based analysis.\n",
    "* Convert InvoiceDate to a proper datetime type so we can filter and group by time later.\n",
    "* Remove any rows where the date could not be parsed.\n",
    "\n",
    "## Why we do it:\n",
    "* Ensures we are working only with valid, complete data before transformations.\n",
    "* Makes sure the InvoiceDate column is in a format that allows filtering and aggregations.\n",
    "* Avoids issues in later steps from missing or invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d49c3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "def extract(file_path):\n",
    "    df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "    df = df.dropna(subset=[\"InvoiceNo\", \"StockCode\", \"Quantity\", \"InvoiceDate\", \"UnitPrice\", \"CustomerID\"])\n",
    "    df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"InvoiceDate\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474a7b3",
   "metadata": {},
   "source": [
    "## Step 2 — Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f46a7b",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Remove invalid transactions:\n",
    "* Negative or zero Quantity values.\n",
    "* Zero or negative UnitPrice.\n",
    "* Create a new column:\n",
    "* TotalSales = Quantity * UnitPrice → This is the key sales measure.\n",
    "* Filter transactions to the last year relative to 2025-08-12 (exam requirement).\n",
    "* Create dimension-like tables:\n",
    "* CustomerDim: unique CustomerID and Country.\n",
    "* TimeDim: unique dates with TimeID, Month, Quarter, Year for time-based OLAP.\n",
    "* Prepare fact table:\n",
    "* SalesFact: contains CustomerID, TimeID, Quantity, and TotalSales.\n",
    "\n",
    "## Why we do it:\n",
    "* Removes bad data so our metrics are accurate.\n",
    "* Adds new calculated metrics for reporting.\n",
    "* Structures the data into star schema format to make OLAP queries easier in Task 3.\n",
    "* Filters for recent transactions to keep analysis relevant and within the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154f31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df[\"TotalSales\"] = df[\"Quantity\"] * df[\"UnitPrice\"]\n",
    "\n",
    "    # Ensure unique customers\n",
    "    customer_dim = df[[\"CustomerID\", \"Country\"]].drop_duplicates(subset=[\"CustomerID\"]).reset_index(drop=True)\n",
    "\n",
    "    # Time dimension\n",
    "    time_df = df[[\"InvoiceDate\"]].drop_duplicates().reset_index(drop=True)\n",
    "    time_df[\"TimeID\"] = time_df.index + 1\n",
    "    time_df[\"Date\"] = time_df[\"InvoiceDate\"].dt.date\n",
    "    time_df[\"Month\"] = time_df[\"InvoiceDate\"].dt.month\n",
    "    time_df[\"Quarter\"] = time_df[\"InvoiceDate\"].dt.quarter\n",
    "    time_df[\"Year\"] = time_df[\"InvoiceDate\"].dt.year\n",
    "    time_dim = time_df[[\"TimeID\", \"Date\", \"Month\", \"Quarter\", \"Year\"]]\n",
    "\n",
    "    # Map TimeID to fact table\n",
    "    df = df.merge(time_df[[\"InvoiceDate\", \"TimeID\"]], on=\"InvoiceDate\", how=\"left\")\n",
    "\n",
    "    # Fact table\n",
    "    sales_fact = df[[\"CustomerID\", \"TimeID\", \"Quantity\", \"TotalSales\"]]\n",
    "\n",
    "    return customer_dim, time_dim, sales_fact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef70eae",
   "metadata": {},
   "source": [
    "## Step 3 — Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3b914",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Connect to a SQLite database (retail_dw.db).\n",
    "* Create tables:\n",
    "* CustomerDim\n",
    "* TimeDim\n",
    "* SalesFact\n",
    "* Load the cleaned/transformed data into these tables.\n",
    "* Enforce foreign key constraints to maintain referential integrity.\n",
    "\n",
    "## Why we do it:\n",
    "* Moves data into a data warehouse structure for analysis.\n",
    "* Allows running SQL queries efficiently in later steps (Task 3).\n",
    "* Ensures we follow proper relational database design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2065ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(customer_dim, time_dim, sales_fact, db_name=\"retail_dw.db\"):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.executescript(\"\"\"\n",
    "    DROP TABLE IF EXISTS SalesFact;\n",
    "    DROP TABLE IF EXISTS TimeDim;\n",
    "    DROP TABLE IF EXISTS CustomerDim;\n",
    "\n",
    "    CREATE TABLE CustomerDim (\n",
    "        CustomerID INTEGER PRIMARY KEY,\n",
    "        Country TEXT\n",
    "    );\n",
    "    CREATE TABLE TimeDim (\n",
    "        TimeID INTEGER PRIMARY KEY,\n",
    "        Date TEXT,\n",
    "        Month INTEGER,\n",
    "        Quarter INTEGER,\n",
    "        Year INTEGER\n",
    "    );\n",
    "    CREATE TABLE SalesFact (\n",
    "        SalesID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        CustomerID INTEGER,\n",
    "        TimeID INTEGER,\n",
    "        Quantity INTEGER,\n",
    "        TotalSales REAL,\n",
    "        FOREIGN KEY (CustomerID) REFERENCES CustomerDim(CustomerID),\n",
    "        FOREIGN KEY (TimeID) REFERENCES TimeDim(TimeID)\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    customer_dim.to_sql(\"CustomerDim\", conn, if_exists=\"append\", index=False)\n",
    "    time_dim.to_sql(\"TimeDim\", conn, if_exists=\"append\", index=False)\n",
    "    sales_fact.to_sql(\"SalesFact\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6268e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Run ETL =====\n",
    "file_path = r\"C:\\Users\\Salma\\New folder\\OneDrive\\Desktop\\DSA 2040_Practical_Exam\\DSA-2040_Practical_Exam_Halima_315\\Online_Retail.csv\"\n",
    "df_extracted = extract(file_path)\n",
    "customer_dim, time_dim, sales_fact = transform(df_extracted)\n",
    "load(customer_dim, time_dim, sales_fact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
