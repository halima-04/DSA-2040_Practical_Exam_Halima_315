{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8202fba7",
   "metadata": {},
   "source": [
    "## Step 1 — Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd457d",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Read the dataset (Online_Retail.csv) from disk into a pandas DataFrame.\n",
    "* Remove rows missing essential values:\n",
    "* InvoiceNo → needed to identify transactions.\n",
    "* StockCode → product identification.\n",
    "* Quantity and UnitPrice → required for sales calculations.\n",
    "* InvoiceDate → needed for time-based analysis.\n",
    "* Convert InvoiceDate to a proper datetime type so we can filter and group by time later.\n",
    "* Remove any rows where the date could not be parsed.\n",
    "\n",
    "## Why we do it:\n",
    "* Ensures we are working only with valid, complete data before transformations.\n",
    "* Makes sure the InvoiceDate column is in a format that allows filtering and aggregations.\n",
    "* Avoids issues in later steps from missing or invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61e3e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid rows before sampling: 397884\n",
      "Sample rows: 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import sqlite3\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Excel from ZIP\n",
    "# -----------------------------\n",
    "zip_path = r\"C:\\Users\\Salma\\Downloads\\online+retail.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    excel_name = z.namelist()[0]\n",
    "    with z.open(excel_name) as f:\n",
    "        df = pd.read_excel(f)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Clean & sample data\n",
    "# -----------------------------\n",
    "# Convert InvoiceDate to datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "# Remove invalid rows\n",
    "df_valid = df.dropna(subset=['CustomerID', 'InvoiceDate'])\n",
    "df_valid = df_valid[(df_valid['Quantity'] > 0) & (df_valid['UnitPrice'] > 0)]\n",
    "\n",
    "print(\"Valid rows before sampling:\", len(df_valid))\n",
    "\n",
    "# Take a 1000-row random sample\n",
    "df_sample = df_valid.sample(n=min(1000, len(df_valid)), random_state=42)\n",
    "print(\"Sample rows:\", len(df_sample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474a7b3",
   "metadata": {},
   "source": [
    "## Step 2 — Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f46a7b",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Remove invalid transactions:\n",
    "* Negative or zero Quantity values.\n",
    "* Zero or negative UnitPrice.\n",
    "* Create a new column:\n",
    "* TotalSales = Quantity * UnitPrice → This is the key sales measure.\n",
    "* Filter transactions to the last year relative to 2025-08-12 (exam requirement).\n",
    "* Create dimension-like tables:\n",
    "* CustomerDim: unique CustomerID and Country.\n",
    "* TimeDim: unique dates with TimeID, Month, Quarter, Year for time-based OLAP.\n",
    "* Prepare fact table:\n",
    "* SalesFact: contains CustomerID, TimeID, Quantity, and TotalSales.\n",
    "\n",
    "## Why we do it:\n",
    "* Removes bad data so our metrics are accurate.\n",
    "* Adds new calculated metrics for reporting.\n",
    "* Structures the data into star schema format to make OLAP queries easier in Task 3.\n",
    "* Filters for recent transactions to keep analysis relevant and within the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e154e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TotalSales\n",
    "df_sample['TotalSales'] = df_sample['Quantity'] * df_sample['UnitPrice']\n",
    "\n",
    "# Customer Dimension\n",
    "customer_dim = df_sample.groupby('CustomerID').agg({\n",
    "    'Country': 'first',\n",
    "    'TotalSales': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Time Dimension\n",
    "time_dim = df_sample[['InvoiceDate']].drop_duplicates().reset_index(drop=True)\n",
    "time_dim['TimeID'] = time_dim.index + 1\n",
    "time_dim['Date'] = time_dim['InvoiceDate']\n",
    "time_dim['Month'] = time_dim['InvoiceDate'].dt.month\n",
    "time_dim['Quarter'] = time_dim['InvoiceDate'].dt.quarter\n",
    "time_dim['Year'] = time_dim['InvoiceDate'].dt.year\n",
    "time_dim = time_dim.drop(columns=['InvoiceDate'])\n",
    "\n",
    "# Map TimeID to SalesFact\n",
    "df_sample = df_sample.merge(time_dim[['Date','TimeID']], left_on='InvoiceDate', right_on='Date', how='left')\n",
    "sales_fact = df_sample[['CustomerID','TimeID','Quantity','TotalSales']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef70eae",
   "metadata": {},
   "source": [
    "## Step 3 — Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3b914",
   "metadata": {},
   "source": [
    "## What we do:\n",
    "* Connect to a SQLite database (retail_dw.db).\n",
    "* Create tables:\n",
    "* CustomerDim\n",
    "* TimeDim\n",
    "* SalesFact\n",
    "* Load the cleaned/transformed data into these tables.\n",
    "* Enforce foreign key constraints to maintain referential integrity.\n",
    "\n",
    "## Why we do it:\n",
    "* Moves data into a data warehouse structure for analysis.\n",
    "* Allows running SQL queries efficiently in later steps (Task 3).\n",
    "* Ensures we follow proper relational database design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4235fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ETL] Completed: retail_dw_sample.db created with:\n",
      "CustomerDim rows: 744\n",
      "TimeDim rows: 950\n",
      "SalesFact rows: 1000\n"
     ]
    }
   ],
   "source": [
    "# 4. Load into SQLite\n",
    "# -----------------------------\n",
    "db_name = \"retail_dw_sample.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop tables if they exist\n",
    "cursor.executescript(\"\"\"\n",
    "DROP TABLE IF EXISTS SalesFact;\n",
    "DROP TABLE IF EXISTS TimeDim;\n",
    "DROP TABLE IF EXISTS CustomerDim;\n",
    "\"\"\")\n",
    "\n",
    "# Create tables\n",
    "cursor.executescript(\"\"\"\n",
    "CREATE TABLE CustomerDim (\n",
    "    CustomerID INTEGER PRIMARY KEY,\n",
    "    Country TEXT,\n",
    "    TotalSales REAL\n",
    ");\n",
    "\n",
    "CREATE TABLE TimeDim (\n",
    "    TimeID INTEGER PRIMARY KEY,\n",
    "    Date TEXT,\n",
    "    Month INTEGER,\n",
    "    Quarter INTEGER,\n",
    "    Year INTEGER\n",
    ");\n",
    "\n",
    "CREATE TABLE SalesFact (\n",
    "    SalesID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    CustomerID INTEGER,\n",
    "    TimeID INTEGER,\n",
    "    Quantity INTEGER,\n",
    "    TotalSales REAL,\n",
    "    FOREIGN KEY (CustomerID) REFERENCES CustomerDim(CustomerID),\n",
    "    FOREIGN KEY (TimeID) REFERENCES TimeDim(TimeID)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert data\n",
    "customer_dim.to_sql('CustomerDim', conn, if_exists='append', index=False)\n",
    "time_dim.to_sql('TimeDim', conn, if_exists='append', index=False)\n",
    "sales_fact.to_sql('SalesFact', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"[ETL] Completed: {db_name} created with:\")\n",
    "print(\"CustomerDim rows:\", len(customer_dim))\n",
    "print(\"TimeDim rows:\", len(time_dim))\n",
    "print(\"SalesFact rows:\", len(sales_fact))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68fd5b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12350, 'Norway', 40.0), (12359, 'Cyprus', 7.800000000000001), (12370, 'Cyprus', 44.550000000000004), (12394, 'Belgium', 16.6), (12415, 'Australia', 282.90000000000003)]\n",
      "[(1, 15034, 1, 6, 12.48), (2, 12528, 2, 12, 35.400000000000006), (3, 15111, 3, 16, 13.28), (4, 14156, 4, 2, 17.0), (5, 13802, 5, 200, 330.0)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"retail_dw_sample.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM CustomerDim LIMIT 5\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "cursor.execute(\"SELECT * FROM SalesFact LIMIT 5\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
